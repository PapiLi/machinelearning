{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]\n",
      " [1]]\n",
      "[[2]]\n",
      "[[2]\n",
      " [2]]\n",
      "[[2]\n",
      " [2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]\n",
      " [1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]\n",
      " [2]]\n",
      "[[2]\n",
      " [2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]\n",
      " [2]]\n",
      "[[2]\n",
      " [2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[2]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "[[1]]\n",
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "def shuffle_data(X, y, seed=None):\n",
    "    if seed:\n",
    "        #这个作用是每次产生一样的随机数\n",
    "        np.random.seed(seed)\n",
    "    #x.shape[0]返回的是行数，以前老师好像说过这里面其实每行是一条数据\n",
    "    #np.arrange返回的是array([0,1,2,3,4])\n",
    "    idx = np.arange(X.shape[0])\n",
    "    #array内序号打乱\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "\n",
    "\n",
    "# 正规化数据集 X\n",
    "def normalize(X, axis=-1, p=2):\n",
    "    #np.linalg.norm按行求向量的范数 ord=2是求2范数 axis=1按行处理\n",
    "    #np.atleast_1d就是将标量化为1维数组，高维保持\n",
    "    #lp_norm就是存了X的每一条数据的l2范数\n",
    "    lp_norm = np.atleast_1d(np.linalg.norm(X, p, axis))\n",
    "    \n",
    "    lp_norm[lp_norm == 0] = 1\n",
    "    #np.expand_dims是将数组按0或1 行或列扩展一个维度\n",
    "    return X / np.expand_dims(lp_norm, axis)\n",
    "\n",
    "\n",
    "# 标准化数据集 X\n",
    "def standardize(X):\n",
    "    #给x的标准差准备一个全是0的数组\n",
    "    X_std = np.zeros(X.shape)\n",
    "    #按行（每一条数据）求均值和方差\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    \n",
    "    # 做除法运算时请永远记住分母不能等于0的情形\n",
    "    # X_std = (X - X.mean(axis=0)) / X.std(axis=0) \n",
    "    for col in range(np.shape(X)[1]):\n",
    "        if std[col]:\n",
    "            X_std[:, col] = (X_std[:, col] - mean[col]) / std[col]\n",
    "\n",
    "    return X_std\n",
    "\n",
    "\n",
    "# 划分数据集为训练集和测试集\n",
    "def train_test_split(X, y, test_size=0.2, shuffle=True, seed=None):\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "\n",
    "    n_train_samples = int(X.shape[0] * (1-test_size))\n",
    "    x_train, x_test = X[:n_train_samples], X[n_train_samples:]\n",
    "    y_train, y_test = y[:n_train_samples], y[n_train_samples:]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], -1)\n",
    "    return np.sum(y == y_pred)/len(y)\n",
    "\n",
    "\n",
    "class KNN():\n",
    "    \"\"\" K近邻分类算法.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k: int\n",
    "        最近邻个数.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    # 计算一个样本与训练集中所有样本的欧氏距离的平方\n",
    "    def euclidean_distance(self, one_sample, X_train):\n",
    "        #-1代表不知道的属性\n",
    "        one_sample = one_sample.reshape(1, -1)\n",
    "        #把x_train数据的形状重设置为行数和未知列数\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        #np.tile将one_sample重复train行 列数就是性值保持 与 train的矩阵\n",
    "        #按行算出欧几里得距离\n",
    "        distances = np.power(np.tile(one_sample, (X_train.shape[0], 1)) - X_train, 2).sum(axis=1)\n",
    "        return distances\n",
    "    \n",
    "    # 获取k个近邻的类别标签\n",
    "    def get_k_neighbor_labels(self, distances, y_train, k):\n",
    "        k_neighbor_labels = []\n",
    "        for distance in np.sort(distances)[:k]:\n",
    "            #难不成是有距离一样的内容 distances==distance这种方式很迷？\n",
    "            label = y_train[distances==distance]\n",
    "            print(label)\n",
    "            #print(label[0])\n",
    "            if(label.shape[0]>1):\n",
    "                label=label.tolist()\n",
    "            k_neighbor_labels.extend(label)\n",
    "\n",
    "        return np.array(k_neighbor_labels).reshape(-1, )\n",
    "    \n",
    "    # 进行标签统计，得票最多的标签就是该测试样本的预测标签\n",
    "    def vote(self, one_sample, X_train, y_train, k):\n",
    "        #算出测试样本点和训练集中所有样本点的距离的数组\n",
    "        distances = self.euclidean_distance(one_sample, X_train)\n",
    "        #print(distances.shape)\n",
    "        y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "        #取距离前k个点的标签\n",
    "        k_neighbor_labels = self.get_k_neighbor_labels(distances, y_train, k)\n",
    "        #print(k_neighbor_labels)\n",
    "        find_label, find_count = 0,0\n",
    "        #Counter类是用来统计标签出现的次数的，Counter({'c': 3, 'a': 2, 'b': 2})\n",
    "        for label, count in Counter(k_neighbor_labels).items():\n",
    "            if count > find_count:\n",
    "                find_count = count\n",
    "                find_label = label\n",
    "        return find_label\n",
    "    \n",
    "    # 对测试集进行预测\n",
    "    def predict(self, X_test, X_train, y_train):\n",
    "        y_pred = []\n",
    "        for sample in X_test:\n",
    "            label = self.vote(sample, X_train, y_train, self.k)\n",
    "            y_pred.append(label)\n",
    "        #print(y_pred)\n",
    "        return np.array(y_pred)\n",
    "\n",
    "\n",
    "def main():\n",
    "    #data = make_classification(n_samples=200, n_features=4, n_informative=2, \n",
    "    #                           n_redundant=2, n_repeated=0, n_classes=2)\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    print(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True)\n",
    "\n",
    "    \n",
    "    clf = KNN(k=5)\n",
    "    y_pred = clf.predict(X_test, X_train, y_train)\n",
    "    \n",
    "    accu = accuracy(y_test, y_pred)\n",
    "    print (\"Accuracy:\", accu)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
